{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e7vPaIoU4pqD"
      },
      "source": [
        "Practice the neural network algorithm by creating a model from scratch only with NumPy. Use of a for loop is  prohibited. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qtWBHOcoqnKH"
      },
      "source": [
        "## 1. Data preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "VA351vjdly0R"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.pipeline import Pipeline\n",
        "RANDOM_STATE = 12579"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "CmAMpQXwdq4t"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Nataqi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\datasets\\_openml.py:968: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
            "  warn(\n"
          ]
        }
      ],
      "source": [
        "X, y = fetch_openml(\"mnist_784\", version=1, return_X_y=True, as_frame=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "gVuTqRrtlb44"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((70000, 784), (70000,))"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X.shape, y.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "YNAjbM-Z8ixF"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<BarContainer object of 10 artists>"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.bar(np.unique(y, return_counts = True)[0], np.unique(y, return_counts = True)[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "GzXvdYtlmNqi"
      },
      "outputs": [],
      "source": [
        "X_normalized = X/255"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "vfx0EL0wmoyU"
      },
      "outputs": [],
      "source": [
        "y_integer = y.astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "SiERfT0gddu1"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_normalized, y_integer, random_state = RANDOM_STATE, test_size=0.2, shuffle = True, stratify = y_integer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "1mujB3I56rjw"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(0.13095012531798408, 0.30847760515635225)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train.mean(), X_train.std()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "TzRs98dodeAF",
        "outputId": "3a6fd962-3567-4616-e2c3-6e6116da3583"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 10 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "fig, ax = plt.subplots(nrows=2, ncols=5, sharex=True, sharey=True)\n",
        "ax = ax.flatten()\n",
        "for i in range(10):\n",
        "  img = X_train[y_train == i][0].reshape(28, 28)\n",
        "  ax[i].imshow(img, cmap='Greys')\n",
        "ax[0].set_xticks([])\n",
        "ax[0].set_yticks([])\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "baT1IBRFqrBJ"
      },
      "source": [
        "## 2. Helper functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "msvnKGsR0yUS"
      },
      "outputs": [],
      "source": [
        "def one_hot(y):\n",
        "  \"\"\"\n",
        "  Input:\n",
        "    - y : set of labels\n",
        "\n",
        "  Output:\n",
        "    - onehot: a one-hot-encoded array\n",
        "\n",
        "  This function creates an one-hot encoded representation of the labels.\n",
        "  This means that you will have a set of binary columns indicading each possible class.\n",
        "\n",
        "  You have to develop this one hot encoding strategy without using Python for loop\n",
        "\n",
        "  Expected outcome:\n",
        "    one_hot(np.array([1,0,2,3]))\n",
        "\n",
        "    array([[0., 1., 0., 0.],\n",
        "          [1., 0., 0., 0.],\n",
        "          [0., 0., 1., 0.],\n",
        "          [0., 0., 0., 1.]])\n",
        "  \"\"\"\n",
        "  one_hot_arr = np.zeros(shape = (len(y), len(np.unique(y))))\n",
        "  one_hot_arr[np.arange(len(y)), y]= 1\n",
        "\n",
        "  return one_hot_arr\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "sGFbZ_tN00WK"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0., 1., 0., 0.],\n",
              "       [1., 0., 0., 0.],\n",
              "       [0., 0., 1., 0.],\n",
              "       [0., 0., 0., 1.]])"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "one_hot(np.array([1,0,2,3]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "hFSCiidT1Drz"
      },
      "outputs": [],
      "source": [
        "def sigmoid(x):\n",
        "  \"\"\"\n",
        "  Input:\n",
        "    - z: input vector or scalar value\n",
        "\n",
        "  Output:\n",
        "    - sigmoid: output sigmoid-transformed vector or scalar value\n",
        "\n",
        "  Calculate the sigmoid value of the input.\n",
        "\n",
        "  Expected outcome:\n",
        "    sigmoid(np.array([np.inf, -np.inf, 0]))\n",
        "\n",
        "    array([1. , 0. , 0.5])\n",
        "  \"\"\"\n",
        "  sigmoid = 1/( 1 + np.exp(-x))\n",
        "\n",
        "  return sigmoid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "3fJNnW22qMQ0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([1. , 0. , 0.5])"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sigmoid(np.array([np.inf, -np.inf, 0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dnfdCK6Fqtls"
      },
      "source": [
        "## 3. Our FCN classifier with the class structure"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "UxEdUv9hmiTd"
      },
      "outputs": [],
      "source": [
        "class FullyConnectedNetwork(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, n_hidden=30, l2= 0., l1=0., epochs=100, eta=0.001, validation_rate = 0.3,\n",
        "                 shuffle=True, batch_size=1, init_technique = \"normal\", seed=None, debug=True):\n",
        "\n",
        "        \"\"\"\n",
        "        The class structure receive the following parameters to construct and test the model:\n",
        "\n",
        "        Input:\n",
        "          - n_hidden: Number of hidden nodes.\n",
        "          - l2: Lambda value for L2-regularization.\n",
        "          - l1: Lambda value for L1-regularization.\n",
        "          - epochs: Number of passes over the training set.\n",
        "          - eta: Learning rate.\n",
        "          - validation_rate: size of the validation set.\n",
        "          - shuffle: Enabling shuffling option of the dataset every epoch.\n",
        "          - batch_size: Number of training examples per batch.\n",
        "          - init_technique: Indicator for an initialization technique.\n",
        "          - seed: Random seed for initializing weights and shuffling.\n",
        "        \"\"\"\n",
        "        self.seed = seed\n",
        "\n",
        "        # DEFINE YOUR RANDOM NUMBER GENERATOR USING THE INPUT SEED\n",
        "        # WARNING! It is strictly required to use \"np.random.default_rng\" to generate random numbers.\n",
        "        self.random = np.random.default_rng(seed) \n",
        "\n",
        "        self.n_hidden = n_hidden\n",
        "        self.l2 = l2\n",
        "        self.l1 = l1\n",
        "        self.epochs = epochs\n",
        "        self.eta = eta\n",
        "        self.validation_rate = validation_rate\n",
        "        self.shuffle = shuffle\n",
        "        self.batch_size = batch_size\n",
        "        self.debug = debug\n",
        "        self.init_technique = init_technique\n",
        "\n",
        "    def compile(self, n_features, n_outputs):\n",
        "        \"\"\"\n",
        "        Initializing the weights of the model\n",
        "\n",
        "        - Here you will initialize bias and weights based on chosen initialization technique.\n",
        "        - The classifier has three different options: normal, xavier, and he\n",
        "        - Each technique initializes the weight using the normal distribution but different standard deviation.\n",
        "        - Use self.init_technique to check the chosen technique and use self.random to perform the sampling.\n",
        "\n",
        "        Input:\n",
        "          - n_features: input size of the network\n",
        "          - n_outputs: output size of the network\n",
        "          - Unit size of the layer is given as self.n_hidden\n",
        "\n",
        "        Steps:\n",
        "          1. Check if you have created self.random using NumPy's random number generator.\n",
        "             You will use this generator throughout this function.\n",
        "          2. Create lists self.W and self.B which will keep the weight values for each layer.\n",
        "          3. Set mean and standard deviation for different initialization technique.\n",
        "          4. Create weights and bias for the linkage between inputs and the first layer.\n",
        "            - Weight should have the size [n_features, self.n_hidden].\n",
        "            - Bias should have the size [self.n_hidden].\n",
        "            - Weight initialization should be applied to the weights only.\n",
        "            - Bias should be initizalied by zeros.\n",
        "          5. Create weights and bias for the linkage between the first layer and the output layer.\n",
        "            - Weight should have the size [self.n_hidden, n_outputs].\n",
        "            - Bias should have the size [n_outputs].\n",
        "            - Weight initialization should be applied to the weights only.\n",
        "            - Bias should be initizalied by zeros.\n",
        "          5. Save the weights to self.W and biases to self.B. Each list should have two elements for each layer.\n",
        "\n",
        "          WARNING! It is strictly required to use \"np.random.default_rng\" to generate random numbers.\n",
        "        \"\"\"\n",
        "\n",
        "        self.B = []\n",
        "        self.W = []\n",
        "\n",
        "        init_mean = 0\n",
        "        std_init_normal = 0.2\n",
        "        std_init_xavier = np.sqrt(2/(n_features + n_outputs))\n",
        "        std_init_xi = np.sqrt(2/n_features)\n",
        "\n",
        "        # 1. Creating weights and bias for [input -> hidden]\n",
        "        # Use specific initialization techniques for weights\n",
        "        # Weights should have the size (n_features, self.n_hidden)\n",
        "        # Use np.zeros for bias with the size 'self.n_hidden'\n",
        "\n",
        "        b_h = np.zeros(self.n_hidden)\n",
        "\n",
        "        if self.init_technique == \"normal\":\n",
        "            w_h = self.random.normal(loc = init_mean, scale = std_init_normal, size = (n_features, self.n_hidden))\n",
        "        elif self.init_technique == \"xavier\":\n",
        "            w_h = self.random.normal(loc = init_mean, scale = std_init_xavier, size = (n_features, self.n_hidden))\n",
        "        elif self.init_technique == \"he\":\n",
        "            w_h = self.random.normal(loc =  init_mean, scale = std_init_xi, size = (n_features, self.n_hidden))\n",
        "           \n",
        "    \n",
        "        # 2. Append bias to self.B and weights to self.W\n",
        "        self.B.append(b_h)\n",
        "        self.W.append(w_h)\n",
        "\n",
        "        # 3. Creating weights and bias for [hidden -> output]\n",
        "        # Use specific initialization techniques for weights\n",
        "        # Weights should have the size (self.n_hidden, n_outputs)\n",
        "        # Use np.zeros for bias with the size 'n_outputs'\n",
        "\n",
        "        b_out = np.zeros(n_outputs)\n",
        "\n",
        "        if self.init_technique == \"normal\":\n",
        "            w_out = self.random.normal(loc = init_mean, scale = std_init_normal, size = (self.n_hidden, n_outputs))\n",
        "        elif self.init_technique == \"xavier\":\n",
        "            w_out = self.random.normal(loc = init_mean, scale = std_init_xavier, size = (self.n_hidden, n_outputs))\n",
        "        elif self.init_technique == \"he\":\n",
        "            w_out = self.random.normal(loc =  init_mean, scale = std_init_xi, size = (self.n_hidden, n_outputs))\n",
        "\n",
        "        # 4. Append bias to self.B and weights to self.W\n",
        "        self.B.append(b_out)\n",
        "        self.W.append(w_out)\n",
        "\n",
        "\n",
        "    def forward(self, X):\n",
        "        \"\"\"\n",
        "        Given the dataset X, compute forward propagation step with the weights and bias saved in the list.\n",
        "        This process eventually outputs ten numbers in our case as the dataset has ten outputs.\n",
        "        (Please refer to the lecture slides for detailed computation process)\n",
        "        Forward propagation is performed by multiple chained dot products of inputs and weights.\n",
        "\n",
        "        Input:\n",
        "          - X: features\n",
        "\n",
        "        Output:\n",
        "          - Z: Result of dot product of the weights and the previous output for each phase\n",
        "          - A: A list that contains sigmoided values of A\n",
        "        Steps:\n",
        "          1. Create two lists Z and A.\n",
        "          2. Take a dot product of X and the first weight self.W[0] - save the result into Z\n",
        "          3. Apply sigmoid function to the first Z - save the result into A\n",
        "          4. Take a dot product of A and the second weight self.W[1] - save the result into Z\n",
        "          5. Apply sigmoid function to the second Z - save the result into A\n",
        "          6. Return Z and A\n",
        "\n",
        "        WARNING! Be careful when you multiply two matrices - think about which rows you are multiplying.\n",
        "                 Wrong order in .dot() function can lead completely wrong result.\n",
        "        \"\"\"\n",
        "\n",
        "        Z = []\n",
        "        A = []\n",
        "\n",
        "        # Step 1: net input of hidden layer\n",
        "        # - You are calculating the first XW+b.\n",
        "        # - Take a dot product of the input features and the initial weights.\n",
        "        # - Add the outcome to list Z.\n",
        "\n",
        "        input_dot = np.dot(X, self.W[0]) + self.B[0]\n",
        "        Z.append(input_dot)\n",
        "\n",
        "        # Step 2: activation of hidden layer\n",
        "        # - Apply the sigmoid function to the dot producted outcome.\n",
        "        # - Add the outcome to list A.\n",
        "\n",
        "        A.append(sigmoid(input_dot)) \n",
        "\n",
        "        # Step 3: net input of output layer\n",
        "        # - You are calculating the second XW+b.\n",
        "        # - Take a dot product of the intermediate features and the weights of the output layer.\n",
        "        # - Add the outcome to list Z.\n",
        "        output_dot = np.dot(A[0], self.W[1]) + self.B[1]  \n",
        "        Z.append(output_dot) \n",
        "\n",
        "        # Step 4: activation output layer\n",
        "        # - Apply the sigmoid function to the dot producted outcome.\n",
        "        # - For simplicity, here the network uses sigmoid instead of softmax.\n",
        "        # - Add the outcome to list A.\n",
        "        A.append(sigmoid(output_dot)) \n",
        "\n",
        "        return Z, A\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\"\n",
        "\n",
        "        Predict class labels by performing forward propagation.\n",
        "\n",
        "        Input:\n",
        "          - X: Feature matrix.\n",
        "        Output:\n",
        "          - y_pred: Predicted class labels for all data instances.\n",
        "\n",
        "        Steps:\n",
        "          1. Run forward proparation on X and get Z, a.\n",
        "          2. Calculate y_pred by using the final output (A[-1]) and with np.argmax\n",
        "            - You have to choose the index of the one with the highest value, which means the highest probability.\n",
        "          3. Return the prediction. You SHOULD perform the operation using NumPy's vectorization feature.\n",
        "             This means that if you put many instances at once as an input, this function should calculate the result also at once.\n",
        "\n",
        "        \"\"\"\n",
        "        Z, A = self.forward(X)\n",
        "        y_pred = np.argmax(A[-1], axis = 1)\n",
        "        \n",
        "      \n",
        "\n",
        "        return y_pred\n",
        "\n",
        "    def cost(self, y_truth, y_pred):\n",
        "        \"\"\"\n",
        "\n",
        "        This function computes the cost for the classification task.\n",
        "        The network supports Elastic net (combination of l1 and l2 with corresponding weights).\n",
        "\n",
        "        Input:\n",
        "          - y_truth: \"One-hot encoded\" class labels.\n",
        "          - y_pred: Activation of the output layer (= output of the forward propagation function).\n",
        "          - The weights for l1 and l2 are saved into self.l1 and self.l2.\n",
        "\n",
        "        Output:\n",
        "          - cost: Regularized cost\n",
        "\n",
        "        Steps:\n",
        "          1. Calculate the cross entropy between the truth (y) and predicted values (y*).\n",
        "             - y * log(y*) - (1 - y) * log(1 - y*)\n",
        "          2. Add l1 and l2 terms to the cost.\n",
        "            - L1 term is the sum of absolute weight values.\n",
        "            - L2 term is the sum of squared weight values.\n",
        "            - You should multiply l1 and l2 ratio saved in self.l1 and self.l2 (this will decide the degree of regularization). \n",
        "            - You should NOT include weights that belong to the bias values.\n",
        "          3. Return the total cost (cross entropy + L1 term + L2 term).\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        L1_term = self.l1 * (np.sum(np.abs(self.W[0])) + np.sum(np.abs(self.W[1])))\n",
        "        L2_term = self.l2 * np.sum(self.W[0]**2) + np.sum(self.W[1]**2)\n",
        "        cost = np.sum(-y_truth * np.log(y_pred) - (1 - y_truth) * np.log(1 - y_pred)) + L1_term + L2_term\n",
        "\n",
        "        return cost\n",
        "\n",
        "\n",
        "\n",
        "    def back_propagation(self, X_train, batch_idx, A, y_truth):\n",
        "      \"\"\"\n",
        "      Perform back propagation based on the result of forward propagation and true labels (for each batch).\n",
        "\n",
        "      Input:\n",
        "        X_train: Training features.\n",
        "        batch_idx: The current batch indices from the fit function.\n",
        "        A: Sigmoided output values - the result of forward propagation.\n",
        "        y_truth: One-hot encoded true labels.\n",
        "\n",
        "      Output:\n",
        "        None\n",
        "        You should update the weights and biases in self.W/self.B\n",
        "\n",
        "      **** You only need to fill in some required parts marked as \"CHANGE THIS PART\" ****\n",
        "      **** To get more information about the backpropagation process:\n",
        "           https://towardsdatascience.com/deriving-backpropagation-with-cross-entropy-loss-d24811edeaf9 ****\n",
        "      \"\"\"\n",
        "\n",
        "      # OUTPUT WEIGHTS (LAYER-OUTPUT)\n",
        "\n",
        "      # C/A * A/Z\n",
        "      delta_out = A[-1] - y_truth[batch_idx]  \n",
        "      # C/A * A/Z * Z/W\n",
        "      grad_w_out = np.dot(A[0].T, delta_out)\n",
        "      # C/A * A/Z * Z/B\n",
        "      grad_b_out = np.sum(delta_out, axis=0)\n",
        "\n",
        "      #############################################\n",
        "      # CHANGE THIS PART\n",
        "\n",
        "      # Using the final gradients of the weight and bias (grad_w_out, grad_b_out), the network needs to update its current weight values.\n",
        "      # The gradient of w and b are already calculated and all you need to do is to merge it with l1/l2 terms.\n",
        "      # Change the values of self.W[1], self.B[1] (output weight and bias).\n",
        "      # - You should also apply l1 and l2 normalization to the weight (not to the bias).       \n",
        "      # - You should use the learning rate (self.eta) when changing the value.\n",
        "\n",
        "      delta_w_out = grad_w_out + self.l1 * np.sign(self.W[1]) + self.l2 * 2 * self.W[1]   \n",
        "      delta_b_out = grad_b_out \n",
        "\n",
        "      self.W[1] = self.W[1] - self.eta * delta_w_out\n",
        "      self.B[1] = self.B[1] - self.eta * delta_b_out\n",
        "\n",
        "      # END OF CHANGE\n",
        "      #############################################\n",
        "\n",
        "      # HIDDEN WEIGHTS (INPUT-LAYER)\n",
        "\n",
        "      #############################################\n",
        "      # CHANGE THIS PART\n",
        "\n",
        "      # To continue to take derivatives backwards, you need to take a derivative of the sigmoid function.\n",
        "      # Here you are trying to take derivative of a sigmoided output A[0].\n",
        "      # Derivative of sigmoid (x) can be represented as (x)(1(x)).\n",
        "\n",
        "      sigmoid_derivative_h = A[0] * (1-A[0])\n",
        "\n",
        "      # END OF CHANGE\n",
        "      #############################################\n",
        "\n",
        "      delta_h = (np.dot(delta_out, self.W[1].T) * sigmoid_derivative_h)\n",
        "      grad_w_h = np.dot(X_train[batch_idx].T, delta_h) \n",
        "      grad_b_h = np.sum(delta_h, axis=0)\n",
        "\n",
        "      #############################################\n",
        "      # CHANGE THIS PART\n",
        "\n",
        "      # Using the final gradients of the weight and bias (grad_w_h, grad_b_h).\n",
        "      # The gradient of w and b are already calculated and all you need to do is to merge it with l1/l2 terms.\n",
        "      # Change the values of self.W[0], self.B[0] (output weight and bias).\n",
        "      # - You should also apply l1 and l2 normalization to the weight (not to the bias).\n",
        "      # - You should use the learning rate (self.eta) when changing the value.\n",
        "\n",
        "      delta_w_h = grad_w_h + self.l1 * np.sign(self.W[0]) + self.l2 * 2 * self.W[0] \n",
        "      delta_b_h = grad_b_h\n",
        "\n",
        "      self.W[0] = self.W[0] - self.eta * delta_w_h\n",
        "      self.B[0] = self.B[0] - self.eta * delta_b_h\n",
        "\n",
        "      # END OF CHANGE\n",
        "      #############################################\n",
        "\n",
        "\n",
        "    def evaluate(self, epoch, X_train, X_valid, y_train, y_valid):\n",
        "\n",
        "      \"\"\"\n",
        "      Evaluate performances on the training and validation sets per epoch\n",
        "\n",
        "      Input:\n",
        "        - epoch: Current epoch number.\n",
        "        - X_train: Training features\n",
        "        - X_valid: Validation features\n",
        "        - y_train: Training labels\n",
        "        - y_valid: Validation labels\n",
        "\n",
        "      Output:\n",
        "        - None\n",
        "        Append the cost and performance metrics of current epoch to self.history\n",
        "      \"\"\"\n",
        "\n",
        "      # Step 1. Call self.forward on X_train to calculate the output with current weights and bias of the model.\n",
        "      Z, A = self.forward(X_train)\n",
        "    \n",
        "\n",
        "      # Step 2. call predict functions with both X_train and X_valid and save the predicted values accordingly.\n",
        "      y_train_pred = self.predict(X_train) \n",
        "      y_valid_pred = self.predict(X_valid)\n",
        "\n",
        "      # Step 2. Call self.cost with one hot encoded y_train and the probability of the output prediction.\n",
        "      # Save it into the variable 'cost'.\n",
        "      cost = self.cost(one_hot(y_train), A[-1])\n",
        "\n",
        "      # Step 4. Calculate accuracy scores.\n",
        "      # - between y_train_pred and y_train.\n",
        "      # - between y_valid_pred and y_valid.\n",
        "      train_acc = np.sum(y_train == y_train_pred)/len(y_train) \n",
        "      valid_acc = np.sum(y_valid == y_valid_pred)/len(y_valid)\n",
        "\n",
        "      # Step 5. Save the results into the dictionary.\n",
        "      # This part is already complete.\n",
        "      if self.debug == True:\n",
        "        print('%d/%d | Cost: %.2f '\n",
        "                        '| Train/Valid Acc.: %.2f%%/%.2f%% ' %\n",
        "                        (epoch+1, self.epochs, cost,\n",
        "                          train_acc*100, valid_acc*100))\n",
        "\n",
        "      self.history['cost'].append(cost)\n",
        "      self.history['train_acc'].append(train_acc)\n",
        "      self.history['valid_acc'].append(valid_acc)\n",
        "\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        \"\"\"\n",
        "\n",
        "        Learn weights from training data.\n",
        "\n",
        "        Input\n",
        "          - X: features (training+validation)\n",
        "          - y: labels\n",
        "\n",
        "        Output\n",
        "          - self.history: information about cost and accuracy scores\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        self.history = {'cost': [], 'train_acc': [], 'valid_acc': []}\n",
        "\n",
        "        # Step 1: Select different training and test sets. Use scikit-learn's train_test_split.\n",
        "        # Turn on the stratification option and use self.validation_rate\n",
        "        X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size = self.validation_rate, stratify = y)\n",
        "        \n",
        "        # Step 2: Compile (initialize) the parameters by running self.compile with correct number of features and outputs\n",
        "        # WRITE YOUR CODE HERE\n",
        "        self.compile(X_train.shape[1], len(np.unique(y))) #initiate weights, update W(w_h,w_out), B(b_h, b_out)\n",
        "\n",
        "        #\n",
        "\n",
        "        # Step 3: Prepare one-hot encoded training labels by using one_hot function on y_train\n",
        "        y_train_enc = one_hot(y_train)\n",
        "\n",
        "        # Step 4: iterate over training epochs\n",
        "        for i in range(self.epochs):\n",
        "\n",
        "            # Step 5: set the indices\n",
        "            # - if self.shuffle is True, shuffle the indices using self.random.shuffle or permutation\n",
        "            indices = np.arange(X_train.shape[0])\n",
        "               \n",
        "            if self.shuffle == True:\n",
        "              self.random.shuffle(indices)\n",
        "\n",
        "          \n",
        "            # Step 6: iterate over the data\n",
        "            # - For each iteration, you need to choose the data\n",
        "            for start_idx in range(0, indices.shape[0] - self.batch_size + 1, self.batch_size):\n",
        "                batch_idx = indices[start_idx:start_idx + self.batch_size]    \n",
        "              \n",
        "                # Step 7: Run a forward propagation\n",
        "                Z, A = self.forward(X_train[batch_idx])\n",
        "                # Step 8: Run back propagation\n",
        "                # - Use X_train, batch_idx, A, and y_train_enc\n",
        "                # WRITE YOUR CODE HERE\n",
        "                self.back_propagation(X_train, batch_idx, A, y_train_enc)\n",
        "\n",
        "                #\n",
        "\n",
        "            # call evaluate function after inner loop (whole batch cycles) is complete\n",
        "            # WRITE YOUR CODE HERE\n",
        "            self.evaluate(i, X_train, X_valid, y_train, y_valid) \n",
        "\n",
        "\n",
        "            #\n",
        "\n",
        "        # Step 9: After all loops are complete, return self.history\n",
        "        return self.history\n",
        "\n",
        "    def transform(self, X, y=None):\n",
        "      \"\"\"\n",
        "      Do not need to complete this function.\n",
        "      Leave as it is!\n",
        "      \"\"\"\n",
        "      return self.history\n",
        "\n",
        "    def score(self, X, y=None):\n",
        "      \"\"\"\n",
        "      Score function for pipeline\n",
        "      Leave as it is!\n",
        "      \"\"\"\n",
        "      y_pred = self.predict(X)\n",
        "      acc = np.sum(y == y_pred) / X.shape[0]\n",
        "      return acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "pEkq3fydrmVw"
      },
      "outputs": [],
      "source": [
        "nn = FullyConnectedNetwork(n_hidden=150, l2=0.01, epochs=30, eta=0.001, batch_size=50, shuffle=True, seed=RANDOM_STATE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "uSKfzn3czNrU"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/30 | Cost: 42960.37 | Train/Valid Acc.: 85.51%/86.15% \n",
            "2/30 | Cost: 34224.02 | Train/Valid Acc.: 88.14%/88.33% \n",
            "3/30 | Cost: 30534.88 | Train/Valid Acc.: 89.27%/89.21% \n",
            "4/30 | Cost: 28104.71 | Train/Valid Acc.: 90.14%/90.12% \n",
            "5/30 | Cost: 26220.32 | Train/Valid Acc.: 90.92%/90.72% \n",
            "6/30 | Cost: 24796.54 | Train/Valid Acc.: 91.48%/91.30% \n",
            "7/30 | Cost: 23769.76 | Train/Valid Acc.: 91.78%/91.53% \n",
            "8/30 | Cost: 22683.89 | Train/Valid Acc.: 92.22%/91.96% \n",
            "9/30 | Cost: 21937.35 | Train/Valid Acc.: 92.49%/92.23% \n",
            "10/30 | Cost: 21165.73 | Train/Valid Acc.: 92.80%/92.49% \n",
            "11/30 | Cost: 20467.13 | Train/Valid Acc.: 93.11%/92.93% \n",
            "12/30 | Cost: 19808.60 | Train/Valid Acc.: 93.30%/92.98% \n",
            "13/30 | Cost: 19173.58 | Train/Valid Acc.: 93.57%/93.27% \n",
            "14/30 | Cost: 18688.41 | Train/Valid Acc.: 93.74%/93.48% \n",
            "15/30 | Cost: 18256.49 | Train/Valid Acc.: 93.91%/93.63% \n",
            "16/30 | Cost: 17788.40 | Train/Valid Acc.: 94.03%/93.79% \n",
            "17/30 | Cost: 17394.16 | Train/Valid Acc.: 94.21%/93.85% \n",
            "18/30 | Cost: 17105.92 | Train/Valid Acc.: 94.34%/94.05% \n",
            "19/30 | Cost: 16706.85 | Train/Valid Acc.: 94.49%/94.08% \n",
            "20/30 | Cost: 16367.71 | Train/Valid Acc.: 94.62%/94.29% \n",
            "21/30 | Cost: 16138.19 | Train/Valid Acc.: 94.67%/94.35% \n",
            "22/30 | Cost: 15784.62 | Train/Valid Acc.: 94.74%/94.42% \n",
            "23/30 | Cost: 15529.02 | Train/Valid Acc.: 95.03%/94.47% \n",
            "24/30 | Cost: 15273.10 | Train/Valid Acc.: 95.13%/94.58% \n",
            "25/30 | Cost: 15031.27 | Train/Valid Acc.: 95.14%/94.55% \n",
            "26/30 | Cost: 14792.27 | Train/Valid Acc.: 95.22%/94.74% \n",
            "27/30 | Cost: 14589.16 | Train/Valid Acc.: 95.39%/94.73% \n",
            "28/30 | Cost: 14360.52 | Train/Valid Acc.: 95.41%/94.86% \n",
            "29/30 | Cost: 14129.86 | Train/Valid Acc.: 95.47%/94.87% \n",
            "30/30 | Cost: 13922.56 | Train/Valid Acc.: 95.59%/94.92% \n"
          ]
        }
      ],
      "source": [
        "history = nn.fit(X_train,y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "n79B9p-OzPIA"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.plot(history['train_acc'])\n",
        "plt.plot(history['valid_acc'])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rPA_LeMzqyFc"
      },
      "source": [
        "## 4. Integrate our classifier into the scikit-learn pipeline and the randomized search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "7KQyD1cf1Na8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/10 | Cost: 65266.57 | Train/Valid Acc.: 78.90%/78.36% \n",
            "2/10 | Cost: 44134.19 | Train/Valid Acc.: 85.42%/84.73% \n",
            "3/10 | Cost: 35474.32 | Train/Valid Acc.: 88.15%/87.15% \n",
            "4/10 | Cost: 30841.69 | Train/Valid Acc.: 89.32%/88.43% \n",
            "5/10 | Cost: 27969.94 | Train/Valid Acc.: 90.11%/89.23% \n",
            "6/10 | Cost: 26183.08 | Train/Valid Acc.: 90.69%/89.84% \n",
            "7/10 | Cost: 24507.00 | Train/Valid Acc.: 91.21%/90.46% \n",
            "8/10 | Cost: 23479.53 | Train/Valid Acc.: 91.47%/90.71% \n",
            "9/10 | Cost: 22600.16 | Train/Valid Acc.: 91.87%/90.96% \n",
            "10/10 | Cost: 21713.53 | Train/Valid Acc.: 92.12%/91.29% \n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;normalizer&#x27;, Normalizer()),\n",
              "                (&#x27;classifier&#x27;, FullyConnectedNetwork(epochs=10))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;normalizer&#x27;, Normalizer()),\n",
              "                (&#x27;classifier&#x27;, FullyConnectedNetwork(epochs=10))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Normalizer</label><div class=\"sk-toggleable__content\"><pre>Normalizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">FullyConnectedNetwork</label><div class=\"sk-toggleable__content\"><pre>FullyConnectedNetwork(epochs=10)</pre></div></div></div></div></div></div></div>"
            ],
            "text/plain": [
              "Pipeline(steps=[('normalizer', Normalizer()),\n",
              "                ('classifier', FullyConnectedNetwork(epochs=10))])"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create: class Normalizer(BaseEstimator, TransformerMixin)\n",
        "#\n",
        "#\n",
        "class Normalizer(BaseEstimator, TransformerMixin):\n",
        "    def transform(self, X, y=None):\n",
        "        X_normalized = (X/225)-0.5\n",
        "\n",
        "        return X_normalized\n",
        "    \n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "    \n",
        "\n",
        "pipe = Pipeline([\n",
        "    ('normalizer', Normalizer()),\n",
        "    ('classifier', FullyConnectedNetwork(epochs=10))]) \n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_integer, random_state = RANDOM_STATE, test_size=0.2, shuffle = True, stratify = y_integer)\n",
        "pipe.fit(X_train, y_train)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "tQRQASa5bz89"
      },
      "outputs": [],
      "source": [
        "pipeline_score = pipe.score(X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "Lcykfo9x6zY8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.9149285714285714\n"
          ]
        }
      ],
      "source": [
        "# PRINT YOUR SCORE HERE\n",
        "print(pipeline_score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "rysn4lmhmpBb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/10 | Cost: 92013.45 | Train/Valid Acc.: 10.49%/10.49% \n",
            "2/10 | Cost: 85505.47 | Train/Valid Acc.: 11.19%/11.19% \n",
            "3/10 | Cost: 84963.29 | Train/Valid Acc.: 11.19%/11.19% \n",
            "4/10 | Cost: 84917.33 | Train/Valid Acc.: 11.19%/11.19% \n",
            "5/10 | Cost: 84913.32 | Train/Valid Acc.: 11.19%/11.19% \n",
            "6/10 | Cost: 84912.98 | Train/Valid Acc.: 11.19%/11.19% \n",
            "7/10 | Cost: 84914.02 | Train/Valid Acc.: 11.19%/11.19% \n",
            "8/10 | Cost: 84912.99 | Train/Valid Acc.: 11.19%/11.19% \n",
            "9/10 | Cost: 84913.82 | Train/Valid Acc.: 11.19%/11.19% \n",
            "10/10 | Cost: 84913.35 | Train/Valid Acc.: 11.19%/11.19% \n",
            "1/10 | Cost: 92049.48 | Train/Valid Acc.: 11.32%/11.32% \n",
            "2/10 | Cost: 85507.98 | Train/Valid Acc.: 11.32%/11.32% \n",
            "3/10 | Cost: 84959.35 | Train/Valid Acc.: 11.32%/11.32% \n",
            "4/10 | Cost: 84914.13 | Train/Valid Acc.: 11.32%/11.32% \n",
            "5/10 | Cost: 84909.60 | Train/Valid Acc.: 11.32%/11.32% \n",
            "6/10 | Cost: 84909.22 | Train/Valid Acc.: 11.32%/11.32% \n",
            "7/10 | Cost: 84909.37 | Train/Valid Acc.: 11.32%/11.32% \n",
            "8/10 | Cost: 84909.25 | Train/Valid Acc.: 11.32%/11.32% \n",
            "9/10 | Cost: 84909.36 | Train/Valid Acc.: 11.32%/11.32% \n",
            "10/10 | Cost: 84909.27 | Train/Valid Acc.: 11.32%/11.32% \n",
            "1/10 | Cost: 91910.43 | Train/Valid Acc.: 10.37%/10.37% \n",
            "2/10 | Cost: 85527.13 | Train/Valid Acc.: 11.25%/11.25% \n",
            "3/10 | Cost: 84963.39 | Train/Valid Acc.: 11.25%/11.25% \n",
            "4/10 | Cost: 84916.48 | Train/Valid Acc.: 11.25%/11.25% \n",
            "5/10 | Cost: 84913.40 | Train/Valid Acc.: 11.25%/11.25% \n",
            "6/10 | Cost: 84911.20 | Train/Valid Acc.: 11.25%/11.25% \n",
            "7/10 | Cost: 84912.16 | Train/Valid Acc.: 11.25%/11.25% \n",
            "8/10 | Cost: 84911.78 | Train/Valid Acc.: 11.25%/11.25% \n",
            "9/10 | Cost: 84911.96 | Train/Valid Acc.: 11.25%/11.25% \n",
            "10/10 | Cost: 84911.63 | Train/Valid Acc.: 11.25%/11.25% \n",
            "1/10 | Cost: 89186.48 | Train/Valid Acc.: 22.88%/23.26% \n",
            "2/10 | Cost: 95034.56 | Train/Valid Acc.: 14.59%/14.48% \n",
            "3/10 | Cost: 95203.04 | Train/Valid Acc.: 11.19%/11.19% \n",
            "4/10 | Cost: 94354.23 | Train/Valid Acc.: 11.19%/11.19% \n",
            "5/10 | Cost: 93304.15 | Train/Valid Acc.: 11.19%/11.19% \n",
            "6/10 | Cost: 91738.61 | Train/Valid Acc.: 11.19%/11.19% \n",
            "7/10 | Cost: 89214.57 | Train/Valid Acc.: 11.19%/11.19% \n",
            "8/10 | Cost: 87264.95 | Train/Valid Acc.: 11.19%/11.19% \n",
            "9/10 | Cost: 86248.17 | Train/Valid Acc.: 11.19%/11.19% \n",
            "10/10 | Cost: 85688.45 | Train/Valid Acc.: 11.19%/11.19% \n",
            "1/10 | Cost: 89290.56 | Train/Valid Acc.: 21.19%/21.02% \n",
            "2/10 | Cost: 95124.60 | Train/Valid Acc.: 11.32%/11.32% \n",
            "3/10 | Cost: 95178.32 | Train/Valid Acc.: 11.32%/11.32% \n",
            "4/10 | Cost: 94380.60 | Train/Valid Acc.: 11.32%/11.32% \n",
            "5/10 | Cost: 93339.53 | Train/Valid Acc.: 11.32%/11.32% \n",
            "6/10 | Cost: 91653.90 | Train/Valid Acc.: 11.32%/11.32% \n",
            "7/10 | Cost: 89072.48 | Train/Valid Acc.: 11.32%/11.32% \n",
            "8/10 | Cost: 87200.02 | Train/Valid Acc.: 11.32%/11.32% \n",
            "9/10 | Cost: 86210.24 | Train/Valid Acc.: 11.32%/11.32% \n",
            "10/10 | Cost: 85665.25 | Train/Valid Acc.: 11.32%/11.32% \n",
            "1/10 | Cost: 88344.98 | Train/Valid Acc.: 25.54%/25.65% \n",
            "2/10 | Cost: 94794.80 | Train/Valid Acc.: 11.25%/11.25% \n",
            "3/10 | Cost: 95201.54 | Train/Valid Acc.: 11.25%/11.25% \n",
            "4/10 | Cost: 94244.92 | Train/Valid Acc.: 11.25%/11.25% \n",
            "5/10 | Cost: 93240.30 | Train/Valid Acc.: 11.25%/11.25% \n",
            "6/10 | Cost: 91618.91 | Train/Valid Acc.: 11.25%/11.25% \n",
            "7/10 | Cost: 89139.09 | Train/Valid Acc.: 11.25%/11.25% \n",
            "8/10 | Cost: 87238.01 | Train/Valid Acc.: 11.25%/11.25% \n",
            "9/10 | Cost: 86227.29 | Train/Valid Acc.: 11.25%/11.25% \n",
            "10/10 | Cost: 85676.85 | Train/Valid Acc.: 11.25%/11.25% \n",
            "1/10 | Cost: 83367.62 | Train/Valid Acc.: 23.33%/23.79% \n",
            "2/10 | Cost: 80824.00 | Train/Valid Acc.: 37.60%/37.80% \n",
            "3/10 | Cost: 78930.79 | Train/Valid Acc.: 46.17%/46.54% \n",
            "4/10 | Cost: 77369.39 | Train/Valid Acc.: 50.64%/50.89% \n",
            "5/10 | Cost: 76049.81 | Train/Valid Acc.: 53.54%/54.03% \n",
            "6/10 | Cost: 74985.48 | Train/Valid Acc.: 57.82%/57.92% \n",
            "7/10 | Cost: 74193.70 | Train/Valid Acc.: 60.22%/60.09% \n",
            "8/10 | Cost: 73721.45 | Train/Valid Acc.: 61.05%/60.69% \n",
            "9/10 | Cost: 73518.06 | Train/Valid Acc.: 62.03%/61.60% \n",
            "10/10 | Cost: 73605.32 | Train/Valid Acc.: 61.09%/60.81% \n",
            "1/10 | Cost: 81935.56 | Train/Valid Acc.: 26.70%/26.48% \n",
            "2/10 | Cost: 78717.00 | Train/Valid Acc.: 37.44%/37.14% \n",
            "3/10 | Cost: 76344.82 | Train/Valid Acc.: 44.19%/44.72% \n",
            "4/10 | Cost: 74477.01 | Train/Valid Acc.: 52.91%/52.99% \n",
            "5/10 | Cost: 73049.38 | Train/Valid Acc.: 55.53%/55.82% \n",
            "6/10 | Cost: 71963.45 | Train/Valid Acc.: 60.64%/60.98% \n",
            "7/10 | Cost: 71268.19 | Train/Valid Acc.: 63.16%/63.45% \n",
            "8/10 | Cost: 70972.76 | Train/Valid Acc.: 62.74%/63.53% \n",
            "9/10 | Cost: 70995.48 | Train/Valid Acc.: 63.30%/64.00% \n",
            "10/10 | Cost: 71241.57 | Train/Valid Acc.: 64.06%/64.57% \n",
            "1/10 | Cost: 81320.36 | Train/Valid Acc.: 27.34%/28.02% \n",
            "2/10 | Cost: 78267.79 | Train/Valid Acc.: 47.66%/47.48% \n",
            "3/10 | Cost: 75904.20 | Train/Valid Acc.: 56.92%/56.66% \n",
            "4/10 | Cost: 73913.44 | Train/Valid Acc.: 60.41%/60.16% \n",
            "5/10 | Cost: 72354.64 | Train/Valid Acc.: 64.36%/64.49% \n",
            "6/10 | Cost: 71243.00 | Train/Valid Acc.: 64.57%/64.85% \n",
            "7/10 | Cost: 70617.58 | Train/Valid Acc.: 66.36%/66.51% \n",
            "8/10 | Cost: 70393.76 | Train/Valid Acc.: 67.12%/67.46% \n",
            "9/10 | Cost: 70464.51 | Train/Valid Acc.: 66.54%/66.82% \n",
            "10/10 | Cost: 70815.85 | Train/Valid Acc.: 68.20%/68.61% \n",
            "1/10 | Cost: 91071.38 | Train/Valid Acc.: 10.23%/10.22% \n",
            "2/10 | Cost: 85218.62 | Train/Valid Acc.: 11.19%/11.19% \n",
            "3/10 | Cost: 84930.10 | Train/Valid Acc.: 11.19%/11.19% \n",
            "4/10 | Cost: 84914.24 | Train/Valid Acc.: 11.19%/11.19% \n",
            "5/10 | Cost: 84913.16 | Train/Valid Acc.: 11.19%/11.19% \n",
            "6/10 | Cost: 84913.18 | Train/Valid Acc.: 11.19%/11.19% \n",
            "7/10 | Cost: 84913.24 | Train/Valid Acc.: 11.19%/11.19% \n",
            "8/10 | Cost: 84913.30 | Train/Valid Acc.: 11.19%/11.19% \n",
            "9/10 | Cost: 84913.66 | Train/Valid Acc.: 11.19%/11.19% \n",
            "10/10 | Cost: 84913.26 | Train/Valid Acc.: 11.19%/11.19% \n",
            "1/10 | Cost: 91042.04 | Train/Valid Acc.: 11.32%/11.32% \n",
            "2/10 | Cost: 85198.09 | Train/Valid Acc.: 11.32%/11.32% \n",
            "3/10 | Cost: 84924.45 | Train/Valid Acc.: 11.32%/11.32% \n",
            "4/10 | Cost: 84911.09 | Train/Valid Acc.: 11.32%/11.32% \n",
            "5/10 | Cost: 84909.76 | Train/Valid Acc.: 11.32%/11.32% \n",
            "6/10 | Cost: 84909.55 | Train/Valid Acc.: 11.32%/11.32% \n",
            "7/10 | Cost: 84909.84 | Train/Valid Acc.: 11.32%/11.32% \n",
            "8/10 | Cost: 84909.60 | Train/Valid Acc.: 11.32%/11.32% \n",
            "9/10 | Cost: 84909.91 | Train/Valid Acc.: 11.32%/11.32% \n",
            "10/10 | Cost: 84910.12 | Train/Valid Acc.: 11.32%/11.32% \n",
            "1/10 | Cost: 91080.41 | Train/Valid Acc.: 9.95%/9.95% \n",
            "2/10 | Cost: 85199.07 | Train/Valid Acc.: 11.25%/11.25% \n",
            "3/10 | Cost: 84929.96 | Train/Valid Acc.: 11.25%/11.25% \n",
            "4/10 | Cost: 84912.98 | Train/Valid Acc.: 11.25%/11.25% \n",
            "5/10 | Cost: 84911.48 | Train/Valid Acc.: 11.25%/11.25% \n",
            "6/10 | Cost: 84912.00 | Train/Valid Acc.: 11.25%/11.25% \n",
            "7/10 | Cost: 84912.54 | Train/Valid Acc.: 11.25%/11.25% \n",
            "8/10 | Cost: 84911.87 | Train/Valid Acc.: 11.25%/11.25% \n",
            "9/10 | Cost: 84912.31 | Train/Valid Acc.: 11.25%/11.25% \n",
            "10/10 | Cost: 84911.72 | Train/Valid Acc.: 11.25%/11.25% \n",
            "1/10 | Cost: 87351.44 | Train/Valid Acc.: 11.19%/11.19% \n",
            "2/10 | Cost: 87097.46 | Train/Valid Acc.: 11.19%/11.19% \n",
            "3/10 | Cost: 87010.60 | Train/Valid Acc.: 11.19%/11.19% \n",
            "4/10 | Cost: 86926.03 | Train/Valid Acc.: 11.19%/11.19% \n",
            "5/10 | Cost: 86857.49 | Train/Valid Acc.: 10.49%/10.49% \n",
            "6/10 | Cost: 86766.19 | Train/Valid Acc.: 11.19%/11.19% \n",
            "7/10 | Cost: 86642.14 | Train/Valid Acc.: 11.19%/11.19% \n",
            "8/10 | Cost: 86336.96 | Train/Valid Acc.: 11.19%/11.19% \n",
            "9/10 | Cost: 85773.20 | Train/Valid Acc.: 11.19%/11.19% \n",
            "10/10 | Cost: 85235.62 | Train/Valid Acc.: 11.19%/11.19% \n",
            "1/10 | Cost: 87362.92 | Train/Valid Acc.: 11.32%/11.32% \n",
            "2/10 | Cost: 87094.55 | Train/Valid Acc.: 11.32%/11.32% \n",
            "3/10 | Cost: 87010.67 | Train/Valid Acc.: 11.32%/11.32% \n",
            "4/10 | Cost: 86926.97 | Train/Valid Acc.: 11.32%/11.32% \n",
            "5/10 | Cost: 86852.96 | Train/Valid Acc.: 11.32%/11.32% \n",
            "6/10 | Cost: 86746.30 | Train/Valid Acc.: 11.32%/11.32% \n",
            "7/10 | Cost: 86593.91 | Train/Valid Acc.: 11.32%/11.32% \n",
            "8/10 | Cost: 86341.94 | Train/Valid Acc.: 11.32%/11.32% \n",
            "9/10 | Cost: 85777.34 | Train/Valid Acc.: 11.32%/11.32% \n",
            "10/10 | Cost: 85258.06 | Train/Valid Acc.: 11.32%/11.32% \n",
            "1/10 | Cost: 87361.87 | Train/Valid Acc.: 11.25%/11.25% \n",
            "2/10 | Cost: 87095.84 | Train/Valid Acc.: 11.25%/11.25% \n",
            "3/10 | Cost: 86985.74 | Train/Valid Acc.: 11.25%/11.25% \n",
            "4/10 | Cost: 86920.85 | Train/Valid Acc.: 11.25%/11.25% \n",
            "5/10 | Cost: 86839.29 | Train/Valid Acc.: 9.86%/9.87% \n",
            "6/10 | Cost: 86739.32 | Train/Valid Acc.: 11.25%/11.25% \n",
            "7/10 | Cost: 86577.13 | Train/Valid Acc.: 11.25%/11.25% \n",
            "8/10 | Cost: 86320.36 | Train/Valid Acc.: 11.25%/11.25% \n",
            "9/10 | Cost: 85786.04 | Train/Valid Acc.: 11.25%/11.25% \n",
            "10/10 | Cost: 85244.88 | Train/Valid Acc.: 11.25%/11.25% \n",
            "1/10 | Cost: 91637.07 | Train/Valid Acc.: 11.19%/11.19% \n",
            "2/10 | Cost: 91113.21 | Train/Valid Acc.: 11.19%/11.19% \n",
            "3/10 | Cost: 90483.77 | Train/Valid Acc.: 11.19%/11.19% \n",
            "4/10 | Cost: 88703.92 | Train/Valid Acc.: 11.19%/11.19% \n",
            "5/10 | Cost: 86394.17 | Train/Valid Acc.: 11.19%/11.19% \n",
            "6/10 | Cost: 85421.24 | Train/Valid Acc.: 11.19%/11.19% \n",
            "7/10 | Cost: 85099.05 | Train/Valid Acc.: 11.19%/11.19% \n",
            "8/10 | Cost: 84982.92 | Train/Valid Acc.: 11.19%/11.19% \n",
            "9/10 | Cost: 84940.62 | Train/Valid Acc.: 11.19%/11.19% \n",
            "10/10 | Cost: 84923.26 | Train/Valid Acc.: 11.19%/11.19% \n",
            "1/10 | Cost: 91634.85 | Train/Valid Acc.: 11.32%/11.32% \n",
            "2/10 | Cost: 91176.28 | Train/Valid Acc.: 11.32%/11.32% \n",
            "3/10 | Cost: 90417.26 | Train/Valid Acc.: 11.32%/11.32% \n",
            "4/10 | Cost: 88725.07 | Train/Valid Acc.: 11.32%/11.32% \n",
            "5/10 | Cost: 86398.67 | Train/Valid Acc.: 11.32%/11.32% \n",
            "6/10 | Cost: 85420.72 | Train/Valid Acc.: 11.32%/11.32% \n",
            "7/10 | Cost: 85094.59 | Train/Valid Acc.: 11.32%/11.32% \n",
            "8/10 | Cost: 84979.39 | Train/Valid Acc.: 11.32%/11.32% \n",
            "9/10 | Cost: 84935.85 | Train/Valid Acc.: 11.32%/11.32% \n",
            "10/10 | Cost: 84919.39 | Train/Valid Acc.: 11.32%/11.32% \n",
            "1/10 | Cost: 91600.57 | Train/Valid Acc.: 11.25%/11.25% \n",
            "2/10 | Cost: 91128.52 | Train/Valid Acc.: 10.37%/10.37% \n",
            "3/10 | Cost: 90395.17 | Train/Valid Acc.: 11.25%/11.25% \n",
            "4/10 | Cost: 88771.68 | Train/Valid Acc.: 11.25%/11.25% \n",
            "5/10 | Cost: 86384.90 | Train/Valid Acc.: 11.25%/11.25% \n",
            "6/10 | Cost: 85418.17 | Train/Valid Acc.: 11.25%/11.25% \n",
            "7/10 | Cost: 85096.58 | Train/Valid Acc.: 11.25%/11.25% \n",
            "8/10 | Cost: 84981.16 | Train/Valid Acc.: 11.25%/11.25% \n",
            "9/10 | Cost: 84938.15 | Train/Valid Acc.: 11.25%/11.25% \n",
            "10/10 | Cost: 84921.91 | Train/Valid Acc.: 11.25%/11.25% \n",
            "1/10 | Cost: 101938.27 | Train/Valid Acc.: 11.19%/11.19% \n",
            "2/10 | Cost: 94383.90 | Train/Valid Acc.: 11.19%/11.19% \n",
            "3/10 | Cost: 87844.55 | Train/Valid Acc.: 11.19%/11.19% \n",
            "4/10 | Cost: 85854.84 | Train/Valid Acc.: 11.19%/11.19% \n",
            "5/10 | Cost: 85243.32 | Train/Valid Acc.: 11.19%/11.19% \n",
            "6/10 | Cost: 85034.28 | Train/Valid Acc.: 11.19%/11.19% \n",
            "7/10 | Cost: 84958.47 | Train/Valid Acc.: 11.19%/11.19% \n",
            "8/10 | Cost: 84930.18 | Train/Valid Acc.: 11.19%/11.19% \n",
            "9/10 | Cost: 84919.43 | Train/Valid Acc.: 11.19%/11.19% \n",
            "10/10 | Cost: 84915.35 | Train/Valid Acc.: 11.19%/11.19% \n",
            "1/10 | Cost: 101508.37 | Train/Valid Acc.: 11.32%/11.32% \n",
            "2/10 | Cost: 94498.10 | Train/Valid Acc.: 11.32%/11.32% \n",
            "3/10 | Cost: 87881.65 | Train/Valid Acc.: 11.32%/11.32% \n",
            "4/10 | Cost: 85864.95 | Train/Valid Acc.: 11.32%/11.32% \n",
            "5/10 | Cost: 85244.84 | Train/Valid Acc.: 11.32%/11.32% \n",
            "6/10 | Cost: 85032.97 | Train/Valid Acc.: 11.32%/11.32% \n",
            "7/10 | Cost: 84955.86 | Train/Valid Acc.: 11.32%/11.32% \n",
            "8/10 | Cost: 84927.16 | Train/Valid Acc.: 11.32%/11.32% \n",
            "9/10 | Cost: 84916.14 | Train/Valid Acc.: 11.32%/11.32% \n",
            "10/10 | Cost: 84911.82 | Train/Valid Acc.: 11.32%/11.32% \n",
            "1/10 | Cost: 101956.68 | Train/Valid Acc.: 11.25%/11.25% \n",
            "2/10 | Cost: 94833.86 | Train/Valid Acc.: 10.18%/10.19% \n",
            "3/10 | Cost: 88057.83 | Train/Valid Acc.: 11.25%/11.25% \n",
            "4/10 | Cost: 85916.73 | Train/Valid Acc.: 11.25%/11.25% \n",
            "5/10 | Cost: 85262.97 | Train/Valid Acc.: 11.25%/11.25% \n",
            "6/10 | Cost: 85040.90 | Train/Valid Acc.: 11.25%/11.25% \n",
            "7/10 | Cost: 84960.13 | Train/Valid Acc.: 11.25%/11.25% \n",
            "8/10 | Cost: 84929.86 | Train/Valid Acc.: 11.25%/11.25% \n",
            "9/10 | Cost: 84918.42 | Train/Valid Acc.: 11.25%/11.25% \n",
            "10/10 | Cost: 84913.93 | Train/Valid Acc.: 11.25%/11.25% \n",
            "1/10 | Cost: 86465.10 | Train/Valid Acc.: 15.54%/15.56% \n",
            "2/10 | Cost: 87558.09 | Train/Valid Acc.: 12.36%/12.38% \n",
            "3/10 | Cost: 89421.35 | Train/Valid Acc.: 11.19%/11.19% \n",
            "4/10 | Cost: 89433.72 | Train/Valid Acc.: 11.19%/11.19% \n",
            "5/10 | Cost: 88709.81 | Train/Valid Acc.: 11.19%/11.19% \n",
            "6/10 | Cost: 88281.99 | Train/Valid Acc.: 11.19%/11.19% \n",
            "7/10 | Cost: 87947.34 | Train/Valid Acc.: 11.19%/11.19% \n",
            "8/10 | Cost: 87659.01 | Train/Valid Acc.: 11.19%/11.19% \n",
            "9/10 | Cost: 87404.56 | Train/Valid Acc.: 11.19%/11.19% \n",
            "10/10 | Cost: 87179.30 | Train/Valid Acc.: 11.19%/11.19% \n",
            "1/10 | Cost: 86924.97 | Train/Valid Acc.: 14.80%/14.34% \n",
            "2/10 | Cost: 87846.78 | Train/Valid Acc.: 11.33%/11.33% \n",
            "3/10 | Cost: 89342.89 | Train/Valid Acc.: 11.32%/11.32% \n",
            "4/10 | Cost: 89366.19 | Train/Valid Acc.: 11.32%/11.32% \n",
            "5/10 | Cost: 88646.07 | Train/Valid Acc.: 11.32%/11.32% \n",
            "6/10 | Cost: 88230.39 | Train/Valid Acc.: 11.32%/11.32% \n",
            "7/10 | Cost: 87902.28 | Train/Valid Acc.: 11.32%/11.32% \n",
            "8/10 | Cost: 87618.47 | Train/Valid Acc.: 11.32%/11.32% \n",
            "9/10 | Cost: 87369.21 | Train/Valid Acc.: 11.32%/11.32% \n",
            "10/10 | Cost: 87146.89 | Train/Valid Acc.: 11.32%/11.32% \n",
            "1/10 | Cost: 86355.73 | Train/Valid Acc.: 14.55%/14.13% \n",
            "2/10 | Cost: 87589.40 | Train/Valid Acc.: 11.52%/11.52% \n",
            "3/10 | Cost: 89383.58 | Train/Valid Acc.: 11.25%/11.25% \n",
            "4/10 | Cost: 89447.48 | Train/Valid Acc.: 11.25%/11.25% \n",
            "5/10 | Cost: 88719.23 | Train/Valid Acc.: 11.25%/11.25% \n",
            "6/10 | Cost: 88284.05 | Train/Valid Acc.: 11.25%/11.25% \n",
            "7/10 | Cost: 87948.42 | Train/Valid Acc.: 11.25%/11.25% \n",
            "8/10 | Cost: 87660.75 | Train/Valid Acc.: 11.25%/11.25% \n",
            "9/10 | Cost: 87406.63 | Train/Valid Acc.: 11.25%/11.25% \n",
            "10/10 | Cost: 87180.91 | Train/Valid Acc.: 11.25%/11.25% \n",
            "1/10 | Cost: 85856.82 | Train/Valid Acc.: 11.19%/11.19% \n",
            "2/10 | Cost: 84930.79 | Train/Valid Acc.: 11.19%/11.19% \n",
            "3/10 | Cost: 84917.59 | Train/Valid Acc.: 11.19%/11.19% \n",
            "4/10 | Cost: 84914.29 | Train/Valid Acc.: 11.19%/11.19% \n",
            "5/10 | Cost: 84914.18 | Train/Valid Acc.: 11.19%/11.19% \n",
            "6/10 | Cost: 84914.02 | Train/Valid Acc.: 11.19%/11.19% \n",
            "7/10 | Cost: 84915.43 | Train/Valid Acc.: 11.19%/11.19% \n",
            "8/10 | Cost: 84914.62 | Train/Valid Acc.: 11.19%/11.19% \n",
            "9/10 | Cost: 84914.98 | Train/Valid Acc.: 11.19%/11.19% \n",
            "10/10 | Cost: 84915.02 | Train/Valid Acc.: 11.19%/11.19% \n",
            "1/10 | Cost: 85831.77 | Train/Valid Acc.: 11.32%/11.32% \n",
            "2/10 | Cost: 84929.42 | Train/Valid Acc.: 11.32%/11.32% \n",
            "3/10 | Cost: 84912.09 | Train/Valid Acc.: 11.32%/11.32% \n",
            "4/10 | Cost: 84910.72 | Train/Valid Acc.: 11.32%/11.32% \n",
            "5/10 | Cost: 84911.52 | Train/Valid Acc.: 11.32%/11.32% \n",
            "6/10 | Cost: 84910.92 | Train/Valid Acc.: 11.32%/11.32% \n",
            "7/10 | Cost: 84912.13 | Train/Valid Acc.: 11.32%/11.32% \n",
            "8/10 | Cost: 84910.80 | Train/Valid Acc.: 11.32%/11.32% \n",
            "9/10 | Cost: 84910.68 | Train/Valid Acc.: 11.32%/11.32% \n",
            "10/10 | Cost: 84910.94 | Train/Valid Acc.: 11.32%/11.32% \n",
            "1/10 | Cost: 85858.48 | Train/Valid Acc.: 11.25%/11.25% \n",
            "2/10 | Cost: 84929.95 | Train/Valid Acc.: 11.25%/11.25% \n",
            "3/10 | Cost: 84913.35 | Train/Valid Acc.: 11.25%/11.25% \n",
            "4/10 | Cost: 84912.03 | Train/Valid Acc.: 11.25%/11.25% \n",
            "5/10 | Cost: 84914.07 | Train/Valid Acc.: 11.25%/11.25% \n",
            "6/10 | Cost: 84912.66 | Train/Valid Acc.: 11.25%/11.25% \n",
            "7/10 | Cost: 84913.48 | Train/Valid Acc.: 11.25%/11.25% \n",
            "8/10 | Cost: 84913.49 | Train/Valid Acc.: 11.25%/11.25% \n",
            "9/10 | Cost: 84913.57 | Train/Valid Acc.: 11.25%/11.25% \n",
            "10/10 | Cost: 84912.78 | Train/Valid Acc.: 11.25%/11.25% \n",
            "1/10 | Cost: 90119.02 | Train/Valid Acc.: 11.19%/11.19% \n",
            "2/10 | Cost: 85766.47 | Train/Valid Acc.: 11.19%/11.19% \n",
            "3/10 | Cost: 84959.69 | Train/Valid Acc.: 11.19%/11.19% \n",
            "4/10 | Cost: 84916.19 | Train/Valid Acc.: 11.19%/11.19% \n",
            "5/10 | Cost: 84913.50 | Train/Valid Acc.: 11.19%/11.19% \n",
            "6/10 | Cost: 84913.89 | Train/Valid Acc.: 11.19%/11.19% \n",
            "7/10 | Cost: 84917.43 | Train/Valid Acc.: 11.19%/11.19% \n",
            "8/10 | Cost: 84913.33 | Train/Valid Acc.: 11.19%/11.19% \n",
            "9/10 | Cost: 84913.61 | Train/Valid Acc.: 11.19%/11.19% \n",
            "10/10 | Cost: 84913.27 | Train/Valid Acc.: 11.19%/11.19% \n",
            "1/10 | Cost: 90074.92 | Train/Valid Acc.: 10.39%/10.39% \n",
            "2/10 | Cost: 85760.85 | Train/Valid Acc.: 11.32%/11.32% \n",
            "3/10 | Cost: 84953.44 | Train/Valid Acc.: 11.32%/11.32% \n",
            "4/10 | Cost: 84912.26 | Train/Valid Acc.: 11.32%/11.32% \n",
            "5/10 | Cost: 84909.51 | Train/Valid Acc.: 11.32%/11.32% \n",
            "6/10 | Cost: 84910.28 | Train/Valid Acc.: 11.32%/11.32% \n",
            "7/10 | Cost: 84912.58 | Train/Valid Acc.: 11.32%/11.32% \n",
            "8/10 | Cost: 84910.27 | Train/Valid Acc.: 11.32%/11.32% \n",
            "9/10 | Cost: 84909.86 | Train/Valid Acc.: 11.32%/11.32% \n",
            "10/10 | Cost: 84910.60 | Train/Valid Acc.: 11.32%/11.32% \n",
            "1/10 | Cost: 90104.42 | Train/Valid Acc.: 9.89%/9.89% \n",
            "2/10 | Cost: 85783.30 | Train/Valid Acc.: 11.25%/11.25% \n",
            "3/10 | Cost: 84955.89 | Train/Valid Acc.: 11.25%/11.25% \n",
            "4/10 | Cost: 84914.81 | Train/Valid Acc.: 11.25%/11.25% \n",
            "5/10 | Cost: 84912.86 | Train/Valid Acc.: 11.25%/11.25% \n",
            "6/10 | Cost: 84913.96 | Train/Valid Acc.: 11.25%/11.25% \n",
            "7/10 | Cost: 84911.97 | Train/Valid Acc.: 11.25%/11.25% \n",
            "8/10 | Cost: 84911.86 | Train/Valid Acc.: 11.25%/11.25% \n",
            "9/10 | Cost: 84911.92 | Train/Valid Acc.: 11.25%/11.25% \n",
            "10/10 | Cost: 84912.39 | Train/Valid Acc.: 11.25%/11.25% \n",
            "1/10 | Cost: 118722.66 | Train/Valid Acc.: 40.69%/40.91% \n",
            "2/10 | Cost: 113164.11 | Train/Valid Acc.: 54.57%/55.04% \n",
            "3/10 | Cost: 109570.40 | Train/Valid Acc.: 56.14%/56.42% \n",
            "4/10 | Cost: 107463.49 | Train/Valid Acc.: 60.43%/60.72% \n",
            "5/10 | Cost: 106374.33 | Train/Valid Acc.: 60.48%/60.88% \n",
            "6/10 | Cost: 106277.33 | Train/Valid Acc.: 61.13%/61.31% \n",
            "7/10 | Cost: 106945.75 | Train/Valid Acc.: 59.01%/59.38% \n",
            "8/10 | Cost: 108066.71 | Train/Valid Acc.: 57.00%/57.49% \n",
            "9/10 | Cost: 109280.94 | Train/Valid Acc.: 56.02%/56.49% \n",
            "10/10 | Cost: 110353.87 | Train/Valid Acc.: 54.61%/55.19% \n"
          ]
        }
      ],
      "source": [
        "parameters = {\"classifier__l1\" : np.arange(0,0.102,0.002), \"classifier__l2\" : np.arange(0,0.102,0.002), \"classifier__n_hidden\" : np.arange(20,110,10), \n",
        "              \"classifier__eta\" : np.arange(0.0001,0.0011,0.0001), \"classifier__init_technique\": ['normal', 'xavier', 'he']}\n",
        "\n",
        "grid = RandomizedSearchCV(estimator = pipe, param_distributions = parameters, n_iter = 10, cv = 3, random_state = RANDOM_STATE)\n",
        "grid.fit(X_train, y_train)\n",
        "\n",
        "best_classifier = grid.best_estimator_\n",
        "best_score = grid.best_score_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "Zisqj2Qk6318"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Pipeline(steps=[('normalizer', Normalizer()),\n",
            "                ('classifier',\n",
            "                 FullyConnectedNetwork(epochs=10, l1=0.008,\n",
            "                                       l2=0.0006000000000000001,\n",
            "                                       n_hidden=90))]) 0.6831075543333092\n"
          ]
        }
      ],
      "source": [
        "# PRINT YOUR SCORES HERE\n",
        "print(best_classifier, best_score)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
